{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6f660-e4f0-403c-bb5b-6d2e10911bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "label_file = open(\"./imagenet-sample/labels.json\")\n",
    "label_file = json.load(label_file)\n",
    "\n",
    "img_to_label = label_file['labels']\n",
    "img_names = list(img_to_label.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01635c0-05c5-4d9a-ab05-ede9e80ae55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "#Define the epsilon constant (L_inf bound)\n",
    "EPS = 2\n",
    "\n",
    "#To constric the GPU choice incase some GPUs are already in use\n",
    "device = \"/device:GPU:1\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.set_visible_devices(gpus[4], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47e747-0dba-492c-9aed-0ccc64768000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image, and add a batch\n",
    "\t# dimension\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "def clip_eps(tensor, eps):\n",
    "\t# clip the values of the tensor to a given range and return it\n",
    "\treturn tf.clip_by_value(tensor, clip_value_min=-eps,\n",
    "\t\tclip_value_max=eps)\n",
    "\n",
    "def generate_adversaries(model, baseImage, delta, classIdx, steps=50):\n",
    "\t# iterate over the number of steps\n",
    "\tfor step in range(0, steps):\n",
    "\t\t# record our gradients\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\t# explicitly indicate that our perturbation vector should\n",
    "\t\t\t# be tracked for gradient updates\n",
    "\t\t\ttape.watch(delta)\n",
    "\t\t\t# add our perturbation vector to the base image and\n",
    "\t\t\t# preprocess the resulting image\n",
    "\t\t\tadversary = preprocess_input(tf.clip_by_value(baseImage + delta, 0, 255))\n",
    "\t\t\t# run this newly constructed image tensor through our\n",
    "\t\t\t# model and calculate the loss with respect to the\n",
    "\t\t\t# *original* class index\n",
    "\t\t\tpredictions = model(adversary, training=False)\n",
    "\t\t\tloss = -sccLoss(tf.convert_to_tensor([classIdx]), predictions)\n",
    "\t\t\t# calculate the gradients of loss with respect to the\n",
    "\t\t\t# perturbation vector\n",
    "\t\t\tgradients = tape.gradient(loss, delta)\n",
    "\t\t\t# update the weights, clip the perturbation vector, and\n",
    "\t\t\t# update its value\n",
    "\t\t\toptimizer.apply_gradients([(gradients, delta)])\n",
    "\t\t\tdelta.assign(clip_eps(delta, eps=EPS))\n",
    "\t# return the perturbation vector\n",
    "\treturn delta\n",
    "\n",
    "# define the learning rate constant\n",
    "LR = 0.1\n",
    "\n",
    "perturbation_list = []\n",
    "\n",
    "ind = 0\n",
    "for img in img_names:\n",
    "\tif(ind!=i):\n",
    "\t\tind+=1\n",
    "\t\tcontinue\n",
    "\ti=i+1\n",
    "\tind=ind+1\n",
    "\tprint(\"Image : \"+str(i))\n",
    "\t# load the input image from disk and preprocess it\n",
    "\timage = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "\timage = preprocess_image(image)\n",
    "\n",
    "\t# load the pre-trained ResNet50 model for running inference\n",
    "\t# print(\"[INFO] loading pre-trained ResNet50 model...\")\n",
    "\tmodel = ResNet50(weights=\"imagenet\")\n",
    "\t# initialize optimizer and loss function\n",
    "\toptimizer = Adam(learning_rate=LR)\n",
    "\tsccLoss = SparseCategoricalCrossentropy()\n",
    "\n",
    "\t# create a tensor based off the input image and initialize the\n",
    "\t# perturbation vector (we will update this vector via training)\n",
    "\tbaseImage = tf.constant(image, dtype=tf.float32)\n",
    "\tdelta = tf.Variable(tf.zeros_like(baseImage), trainable=True)\n",
    "\t# generate the perturbation vector to create an adversarial example\n",
    "\tdeltaUpdated = generate_adversaries(model, baseImage, delta, img_to_label[img])\n",
    "\t\n",
    "\tperturbation_list.append(deltaUpdated)\n",
    "\tnp.save('perturbations.npy',np.array(perturbation_list))\n",
    "\t\n",
    "\t# create the adversarial example, swap color channels, and save the\n",
    "\t# output image to disk\n",
    "\tadverImage = (baseImage + deltaUpdated).numpy().squeeze()\n",
    "\tadverImage = np.clip(adverImage, 0, 255).astype(\"uint8\")\n",
    "\tadverImage = cv2.cvtColor(adverImage, cv2.COLOR_RGB2BGR)\n",
    "\tcv2.imwrite('./adv_png/'+img+'_adversarial.png', adverImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3dbe2-2511-4fd9-b2d9-aa3d02a149f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "perturbation_list = np.load('perturbations.npy')\n",
    "print(np.min(perturbation_list))\n",
    "print(np.max(perturbation_list))\n",
    "perturbation_list = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
