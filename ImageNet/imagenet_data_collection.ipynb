{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6f660-e4f0-403c-bb5b-6d2e10911bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "label_file = open(\"./imagenet-sample/labels.json\")\n",
    "label_file = json.load(label_file)\n",
    "labels_to_name = label_file['classes']\n",
    "img_to_label = label_file['labels']\n",
    "img_names = list(img_to_label.keys())\n",
    "\n",
    "json_items = json.load(open(\"./imagenet-sample/imagenet_class_index.json\")).items()\n",
    "imageNetClasses = {labels[1]: int(idx) for (idx, labels) in json_items}\n",
    "def get_class_idx(label):\n",
    "\treturn imageNetClasses.get(label, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01635c0-05c5-4d9a-ab05-ede9e80ae55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To select GPU\n",
    "device = \"/device:GPU:1\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.set_visible_devices(gpus[4], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013dfc4-6d96-4db4-9178-145064e681db",
   "metadata": {},
   "source": [
    "# To check the Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e1a42-ae95-41d6-b8be-156eddd7904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "#Check Accuracy of model on Original Images and Perturbed Images\n",
    "org_acc = 0\n",
    "adv_acc = 0\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "model = ResNet50(weights=\"imagenet\")\n",
    "\n",
    "img_list = []\n",
    "true_label_list = []\n",
    "\n",
    "for img in img_names:\n",
    "    image = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "    image = preprocess_image(image)\n",
    "    image = tf.constant(image, dtype=tf.float32)\n",
    "    img_list.append(image)\n",
    "    true_label_list.append(img_to_label[img])\n",
    "\n",
    "img_list = np.array(img_list)\n",
    "\n",
    "preprocessedImage = preprocess_input(tf.constant(img_list, dtype=tf.float32))\n",
    "\n",
    "predictions = model.predict(preprocessedImage)\n",
    "predictions = np.array(decode_predictions(predictions, top=3))[:,0,1]\n",
    "\n",
    "for index1 in range(0,1000):\n",
    "    if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "        org_acc+=1\n",
    "\n",
    "perturbations = np.load('perturbations.npy').squeeze()\n",
    "scale = 1\n",
    "\n",
    "preprocessedImage = preprocess_input(tf.constant(tf.clip_by_value((img_list+scale*perturbations), 0, 255).numpy().astype('uint8'), dtype=tf.float32))\n",
    "\n",
    "predictions = model.predict(preprocessedImage)\n",
    "predictions = np.array(decode_predictions(predictions, top=3))[:,0,1]\n",
    "\n",
    "for index1 in range(0,1000):\n",
    "    if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "        adv_acc+=1\n",
    "\n",
    "print(org_acc) #716\n",
    "print(adv_acc) # 58_1, 57_2, 56_4, 57_8, 33_16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb76cb34-f001-4ae4-9095-3361d0818764",
   "metadata": {},
   "source": [
    "# To check trasferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972f6e1-78fe-4fb7-b896-1e887d1362c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "i = 0\n",
    "\n",
    "model = ResNet50(weights=\"imagenet\")\n",
    "\n",
    "img_list = []\n",
    "true_label_list = []\n",
    "\n",
    "for img in img_names:\n",
    "    image = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "    image = preprocess_image(image)\n",
    "    adversarialImage = tf.constant(image, dtype=tf.float32)\n",
    "    img_list.append(adversarialImage)\n",
    "    true_label_list.append(img_to_label[img])\n",
    "\n",
    "img_list = np.array(img_list)\n",
    "\n",
    "acc_list = []\n",
    "perturbations = np.load('perturbations.npy')\n",
    "scale = 1\n",
    "\n",
    "for index in range(0,1000):\n",
    "    predictions = model.predict(preprocess_input(tf.constant(tf.clip_by_value((img_list+scale*perturbations[index]), 0, 255).numpy().astype('uint8'), dtype=tf.float32)))\n",
    "    predictions = np.array(decode_predictions(predictions, top=3))[:,0,1]\n",
    "    \n",
    "    count = 0\n",
    "    accuracy = 0\n",
    "    for index1 in range(0,1000):\n",
    "        if(index == index1):\n",
    "            continue\n",
    "        count+=1\n",
    "        if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "            accuracy+=1\n",
    "    acc_list.append(accuracy)\n",
    "    print(str(index)+' '+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4e928-cdf1-402f-a927-3e1319749210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(acc_list).sum()/9990.0) # 712858,71.36_1 -- 711005,71.17_2 -- 697854,69.85_4 -- 704216,70.49_8 -- 693092,69.38_16\n",
    "\n",
    "# print(org_acc) #716\n",
    "# print(adv_acc) #60(jpg), 57(png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4aef6-432d-44e6-bc96-d16c216994a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Plot the images with their label, predicted label and cofidence of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96549450-2b40-44d4-9c44-fe77a4251017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the images with their label, predicted label and cofidence of prediction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ind_list = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "\n",
    "for ind in ind_list:\n",
    "    img = img_names[ind]\n",
    "\n",
    "    image = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "    testImage = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (224, 224))\n",
    "    image = preprocess_image(image)\n",
    "    baseImage = tf.constant(image, dtype=tf.float32)\n",
    "    \n",
    "    image = cv2.imread('./adv_png/'+img+'_adversarial.png')\n",
    "    testImage_adv = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (224, 224))\n",
    "    image = preprocess_image(image)\n",
    "    adversarialImage = tf.constant(image, dtype=tf.float32)\n",
    "    \n",
    "    preprocessedImage = preprocess_input(baseImage)\n",
    "    predictions = model.predict(preprocessedImage)\n",
    "    predictions = decode_predictions(predictions, top=3)[0]\n",
    "    label = labels_to_name[get_class_idx(predictions[0][1])]\n",
    "    confidence = predictions[0][2] * 100\n",
    "    \n",
    "    preprocessedImage = preprocess_input(adversarialImage)\n",
    "    predictions = model.predict(preprocessedImage)\n",
    "    predictions = decode_predictions(predictions, top=3)[0]\n",
    "    label_adv = labels_to_name[get_class_idx(predictions[0][1])]\n",
    "    confidence_adv = predictions[0][2] * 100\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 2, figsize = (12, 6))\n",
    "    fig.suptitle(labels_to_name[img_to_label[img]],size=30, fontweight='bold')\n",
    "    fig.tight_layout(pad = 0.5, rect = (0,0.08,1,1))\n",
    "    \n",
    "    ax[0].imshow(testImage)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(f\"Prediction : {label} \\n Confidence : {confidence:.3f}%\", size = 20, y=-0.15)\n",
    "    ax[1].imshow(testImage_adv)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(f\"Prediction : {label_adv} \\n Confidence : {confidence_adv:.3f}%\", size = 20, y=-0.15)\n",
    "    plt.savefig('op_png/'+str(ind)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98301f24-33f8-4dde-adea-81620a7d1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ind_list = [[0, 100], [200, 300], [400, 500], [600, 700], [800, 900]]\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize = (80, 16))\n",
    "fig.tight_layout(pad = 0.0)\n",
    "\n",
    "for ind in range(5):\n",
    "    image1 = cv2.cvtColor(cv2.imread('op_png/'+str(ind_list[ind][0])+'.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    image2 = cv2.cvtColor(cv2.imread('op_png/'+str(ind_list[ind][1])+'.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    ax[0, ind].imshow(image1)\n",
    "    ax[0, ind].axis(\"off\")\n",
    "    ax[1, ind].imshow(image2)\n",
    "    ax[1, ind].axis(\"off\")\n",
    "plt.savefig('output_image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10917e0-3abb-4c9d-b269-7f1012ea55c5",
   "metadata": {},
   "source": [
    "# Effect of Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc237f0-c60d-42ae-91b5-91e9b839e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Effect of noise\n",
    "\n",
    "# import necessary packages\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "model = ResNet50(weights=\"imagenet\")\n",
    "\n",
    "img_list = []\n",
    "true_label_list = []\n",
    "\n",
    "for img in img_names:\n",
    "    image = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "    image = preprocess_image(image)\n",
    "    adversarialImage = tf.constant(image, dtype=tf.float32)\n",
    "    img_list.append(adversarialImage)\n",
    "    true_label_list.append(img_to_label[img])\n",
    "\n",
    "img_list = np.array(img_list)\n",
    "\n",
    "acc_list = []\n",
    "noise_list = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "for noise in noise_list:\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    predictions = model.predict(preprocess_input(tf.constant(tf.clip_by_value((img_list+np.random.normal(size = img_list.shape, loc = 0, scale = noise)), 0, 255).numpy().astype('uint8'), dtype=tf.float32)))\n",
    "    predictions = np.array(decode_predictions(predictions, top=3))[:,0,1]\n",
    "    \n",
    "    accuracy = 0\n",
    "    for index1 in range(0,1000):\n",
    "        if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "            accuracy+=1\n",
    "    acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784dcc00-9fe2-4ae6-89aa-41f78964bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_list) #(714, 714, 704, 693, 611, 463, 139, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a186342-3ba1-43a3-bd3c-e8c37268f4b9",
   "metadata": {},
   "source": [
    "## Plot Accuracy of Random Noise compared to Adversarial Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be7f46-3a05-40f4-83be-fdebaa8eec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 6))\n",
    "\n",
    "x_noise = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "y_noise = [71.4, 71.4, 70.4, 69.3, 61.1, 46.3, 13.9, 0.3]\n",
    "x_adv = [0, 1, 2, 3, 4]\n",
    "y_adv = [5.8, 5.7, 5.6, 5.7, 3.3]\n",
    "\n",
    "x_orig = [-1, 9]\n",
    "y_orig = [71.6, 71.6]\n",
    "\n",
    "plt.xlim([0, 8])\n",
    "plt.ylim([0, 100])\n",
    "\n",
    "plt.xlabel('EPS/Std-Dev (log scale)', size = 'xx-large')\n",
    "plt.ylabel('Accuracy (%)', size = 'xx-large')\n",
    "\n",
    "plt.plot(x_orig, y_orig, label = 'Base Accuracy', ls = '--')\n",
    "plt.plot(x_adv, y_adv, label = 'Accuracy on Adversarial Images')\n",
    "plt.plot(x_noise, y_noise, label = 'Accuracy on Random Gaussian Perturbation')\n",
    "\n",
    "plt.xticks(range(0, 9), [1, 2, 4, 8, 16, 32, 64, 128, 256])\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('noise_vs_adv.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3356f-3433-40b7-982b-2b4449d8f28e",
   "metadata": {},
   "source": [
    "# Transferability to Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593b85c-6661-4bbe-a240-f016eed47283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transferability to Different Models\n",
    "\n",
    "# import necessary packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras.applications.mobilenet_v2 as mn\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "img_list = []\n",
    "true_label_list = []\n",
    "\n",
    "for img in img_names:\n",
    "    image = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "    image = preprocess_image(image)\n",
    "    image = tf.constant(image, dtype=tf.float32)\n",
    "    img_list.append(image)\n",
    "    true_label_list.append(img_to_label[img])\n",
    "\n",
    "img_list = np.array(img_list)\n",
    "\n",
    "model = mn.MobileNetV2(weights=\"imagenet\")\n",
    "\n",
    "acc = 0\n",
    "\n",
    "predictions = model.predict(mn.preprocess_input(tf.constant(img_list, dtype=tf.float32)))\n",
    "predictions = np.array(mn.decode_predictions(predictions, top=3))[:,0,1]\n",
    "\n",
    "for index1 in range(0,1000):\n",
    "    if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "        acc+=1\n",
    "print(acc) #709\n",
    "\n",
    "acc = 0\n",
    "perturbations = np.load('perturbations.npy').squeeze()\n",
    "scale = 1\n",
    "\n",
    "predictions = model.predict(mn.preprocess_input(tf.constant(tf.clip_by_value((img_list+scale*perturbations), 0, 255).numpy().astype('uint8'), dtype=tf.float32)))\n",
    "predictions = np.array(mn.decode_predictions(predictions, top=3))[:,0,1]\n",
    "\n",
    "for index1 in range(0,1000):\n",
    "    if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "        acc+=1\n",
    "print(acc) # 658_1, 601_2, 490_4, 536_8, 486_16, _32, _64 / 331_4*2, 198_8*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4559f5-72ab-4aaa-9f57-6951a0f83d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transferability to Different Models\n",
    "\n",
    "# import necessary packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras.applications.vgg16 as vgg\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "img_list = []\n",
    "true_label_list = []\n",
    "\n",
    "for img in img_names:\n",
    "    image = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "    image = preprocess_image(image)\n",
    "    image = tf.constant(image, dtype=tf.float32)\n",
    "    img_list.append(image)\n",
    "    true_label_list.append(img_to_label[img])\n",
    "\n",
    "img_list = np.array(img_list)\n",
    "\n",
    "model =  vgg.VGG16(weights=\"imagenet\")\n",
    "\n",
    "acc = 0\n",
    "\n",
    "predictions = model.predict(vgg.preprocess_input(tf.constant(img_list, dtype=tf.float32)))\n",
    "predictions = np.array(vgg.decode_predictions(predictions, top=3))[:,0,1]\n",
    "\n",
    "for index1 in range(0,1000):\n",
    "    if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "        acc+=1\n",
    "print(acc) #651\n",
    "\n",
    "acc = 0\n",
    "perturbations = np.load('perturbations.npy').squeeze()\n",
    "scale = 1\n",
    "\n",
    "predictions = model.predict(vgg.preprocess_input(tf.constant(tf.clip_by_value((img_list+scale*perturbations), 0, 255).numpy().astype('uint8'), dtype=tf.float32)))\n",
    "predictions = np.array(vgg.decode_predictions(predictions, top=3))[:,0,1]\n",
    "\n",
    "for index1 in range(0,1000):\n",
    "    if(true_label_list[index1] == get_class_idx(predictions[index1])):\n",
    "        acc+=1\n",
    "print(acc) # 604_1, 569_2, 475_4, 528_8, 480_16 / 323_4*2, 189_8*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc61541-eaed-4def-b3eb-7fc14b7bd6cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# To Save the Images otained after applying perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ad562-d986-4acc-8366-7ed45b2e46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save the images\n",
    "\n",
    "def preprocess_image(image):\n",
    "\t# swap color channels, resize the input image, and add a batch\n",
    "\t# dimension\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\t# return the preprocessed image\n",
    "\treturn image\n",
    "\n",
    "perturbation_list = np.load('perturbations_float.npy')\n",
    "\n",
    "for i in range(0,1000):\n",
    "\tprint(i+1)\n",
    "\timg = img_names[i]\n",
    "\timage = cv2.imread('./imagenet-sample/data/'+img+'.jpg')\n",
    "\timage = preprocess_image(image)\n",
    "\tbaseImage = tf.constant(image, dtype=tf.float32)\n",
    "\tadverImage = (baseImage + perturbation_list[i]).numpy().squeeze()\n",
    "\tadverImage = np.clip(adverImage, 0, 255).astype(\"uint8\")\n",
    "\tadverImage = cv2.cvtColor(adverImage, cv2.COLOR_RGB2BGR)\n",
    "\tcv2.imwrite('./adv_png/'+img+'_adversarial.png', adverImage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
